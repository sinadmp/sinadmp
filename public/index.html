
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>Hexo</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="John Doe">
    

    
    <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
<meta name="twitter:description">

    
    <link rel="alternative" href="/atom.xml" title="Hexo" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Hexo" title="Hexo"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Hexo">Hexo</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜單">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:yoursite.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/02/23/hello-world/" title="Hello World" itemprop="url">Hello World</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="John Doe" target="_blank" itemprop="author">John Doe</a>
		
  <p class="article-time">
    <time datetime="2016-02-23T10:06:41.000Z" itemprop="datePublished"> 發表於 2016-02-23</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/02/23/ADMM调研/" title="ADMM调研" itemprop="url">ADMM调研</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="John Doe" target="_blank" itemprop="author">John Doe</a>
		
  <p class="article-time">
    <time datetime="2016-02-23T09:30:31.000Z" itemprop="datePublished"> 發表於 2016-02-23</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="ADMM调研"><a href="#ADMM调研" class="headerlink" title="ADMM调研"></a>ADMM调研</h2><h3 id="1-约束优化问题一般解决方案"><a href="#1-约束优化问题一般解决方案" class="headerlink" title="1. 约束优化问题一般解决方案"></a>1. 约束优化问题一般解决方案</h3><h4 id="1-1-Dual-Ascent（对偶上升法）"><a href="#1-1-Dual-Ascent（对偶上升法）" class="headerlink" title="1.1. Dual Ascent（对偶上升法）"></a>1.1. <strong>Dual Ascent（对偶上升法）</strong></h4><p>对于凸函数的优化问题，对偶上升法对偶上升法核心思想就是引入一个对偶变量，然后利用交替优化的思路，使得两者同时达到optimal。</p>
<p>一个典型的等式约束最优化问题，形式化表示如下：</p>
<p>$$<br>\begin{align}<br>&amp;\min_{x} \quad f(x) \\<br>&amp; s.t. \; Ax=b<br>\end{align}<br>$$</p>
<p>目标函数是\(f(x)\)，\(x=(x_1,x_2,\cdots,x_n)^T \in R^n\) （\(n\)表示参数向量个数）；下面是等式约束。</p>
<p>引入拉格朗日乘子（又称算子），这里用\(\beta\)表示乘子，得到的拉格朗日公式为：</p>
<p>$$\mathcal{L}(x,\beta) = f(x) + \beta^T (Ax-b) \qquad(1.2)$$</p>
<p>对偶函数：</p>
<p>$$<br>    g(\beta) = \inf_{x} L(x,\beta) \qquad(1.3)<br>    $$</p>
<p>在强对偶性假设下，即最小化原凸函数（primal）等价于最大化对偶函数（dual），两者会同时达到optimal。可得：</p>
<p>$$<br>    x^{*} = \arg \min_{x} \mathcal{L}(x, y^{*})  \qquad(1.4)<br>    $$</p>
<p>如果对偶函数\(g(\beta)\)可导，使用Dual Ascent法，交替更新参数，使得同时收敛到最优。迭代公式如下：</p>
<p>$$<br>\begin{align}<br>x^{k+1} &amp; := \arg \min_{x} L(x,\beta^{k}) \quad（x-最小化）\\<br>\beta^{k+1} &amp; := \beta^{k} + \alpha^k \nabla g(\beta) = y^k + \alpha^k(A x^{k+1} -b) \quad (对偶变量更新，\alpha^k为步长)<br>\end{align} \qquad(1.5)<br>$$</p>
<p>Dual Ascent法要求目标函数\(f(x)\)为<strong>强凸函数</strong>（一般的目标函数难以满足）。</p>
<blockquote>
<p>强凸函数</p>
<p>函数\(f: I \rightarrow R\) 成为强凸的，若\(\exists \alpha &gt; 0\)，使\(\forall (x,y) \in I \times I, \forall t \in [0,1]\)，恒有：</p>
</blockquote>
<p>$$<br>f[t x + (1-t)y] \le tf(x) + (1-t) f(y) - t(1-t)\alpha(x-y)^2<br>$$</p>
<h4 id="1-2-Dual-Decomposition"><a href="#1-2-Dual-Decomposition" class="headerlink" title="1.2. Dual Decomposition"></a>1.2. Dual Decomposition</h4><p>Dual Ascent的缺陷就是它对目标函数的限制过于严格。但是它有一个非常好的性质：</p>
<p><strong>当目标函数\(f\)可分（separable）时，整个问题可以拆解成多个子问题，分块优化后得到局部参数，然后汇集起来整体更新全局参数。非常有利于并行化处理。</strong></p>
<p>形式化表示：</p>
<p>$$<br>\begin{align}<br>&amp; \min_{x} \quad f(x) = \sum_{i=1}^{m} f_i(x_i) \\<br>&amp; s.t. \; Ax=\sum_{i=1}^{m} A_ix_i = b<br>\end{align}        \qquad(1.6)<br>$$</p>
<p>拉格朗日函数：</p>
<p>$$<br>\mathcal{L}(x,\beta) = \sum_{i=1}^{m} \mathcal{L}_i(x_i, \beta) = \sum_{i=1}^{m} \left(f_i(x_i) + \beta^T A_i x_i - \frac{1}{N} \beta^T b \right) \qquad(1.7)<br>$$</p>
<p>对应的迭代公式：</p>
<p>$$<br>\begin{align}<br>x_{i}^{k+1} &amp; := \arg \min_{x} L_i(x_i,\beta^{k}) \quad（多个x_i并行最小化步）\quad(1)\\<br>\beta^{k+1} &amp; := \beta^{k} + \alpha^k \nabla g(\beta) = y^k + \alpha^k(A x^{k+1} -b) \quad (汇集整体的x,对偶变量更新) \quad(2)<br>\end{align} \qquad\qquad(1.8)<br>$$</p>
<h4 id="1-3-扩展拉格朗日乘子法"><a href="#1-3-扩展拉格朗日乘子法" class="headerlink" title="1.3. 扩展拉格朗日乘子法"></a>1.3. 扩展拉格朗日乘子法</h4><p>dual ascent方法对于目标函数要求比较苛刻，为了放松假设条件，同时比较好优化，于是就有了Augmented Lagrangians方法，目的就是放松对于\(f(x)\)严格凸的假设和其他一些条件，同时还能使得算法更加稳健。</p>
<p>具体做法：原有的拉格朗日公式添加惩罚函数项：</p>
<p>$$<br>\mathcal{L}_{\rho}(x,\beta) = f(x) + \beta^T (Ax-b) + \frac{\rho}{2} {\Vert Ax-b \Vert}_2^2 \qquad(1.9)<br>$$</p>
<p>公式解读：</p>
<blockquote>
<p>$$<br>\mathcal{L}_{\rho}(x,\beta) = f(x) + \overbrace{ \underbrace{\beta^T (Ax-b)}_{拉格朗日乘子法} + \underbrace{ \frac{\rho}{2} {\Vert Ax-b \Vert}_2^2}_{函数惩罚法} }^{增强拉格朗日乘子法} \qquad(n.1.1)<br>$$    </p>
</blockquote>
<p>参数迭代公式</p>
<p>$$<br>\begin{align}<br>x^{k+1} &amp; := \arg \min_{x} L(x,\beta^{k}) \quad（x-最小化）\\<br>\beta^{k+1} &amp; := \beta^{k} + \alpha^k \nabla g(\beta) = y^k + \rho(A x^{k+1} -b) \quad (对偶变量更新，\alpha^k为步长)<br>\end{align} \qquad(1.10)<br>$$</p>
<p>虽然Augmented Lagrangians方法有优势，但也破坏了dual ascent方法的利用分解参数来并行的优势。当\(f\)是separable时，对于Augmented Lagrangians却是not separable的（因为平方项写成矩阵形式无法用之前那种分块形式）</p>
<h3 id="2-Alternating-Direction-Method-of-Multipliers-ADMM"><a href="#2-Alternating-Direction-Method-of-Multipliers-ADMM" class="headerlink" title="2. Alternating Direction Method of Multipliers (ADMM)"></a>2. Alternating Direction Method of Multipliers (ADMM)</h3><h4 id="2-1-ADMM概述"><a href="#2-1-ADMM概述" class="headerlink" title="2.1. ADMM概述"></a>2.1. ADMM概述</h4><p>为了整合dual ascent可分解性与method multiplers优秀的收敛性质，人们就又提出了改进形式的优化ADMM。目的就是想能分解原函数和扩增函数，以便于在对\(f(x)\)更一般的假设条件下并行优化。</p>
<p>ADMM从名字可以看到是在原来Method of Multipliers加了个Alternating Direction，可以大概猜想到应该是又想引入新变量，然后交叉换方向来交替优化。形式如下：</p>
<p>$$<br>\begin{align}<br>&amp; min \quad f(x) + g(z)  \\<br>&amp; s.b \quad Ax + B z = C<br>\end{align}  \qquad (2.1)<br>$$</p>
<blockquote>
<p>其中\(x \in R^n, z \in R^m; A \in R^{p \times n}, B \in R^{p \times m}, C \in R^p\)。</p>
</blockquote>
<p>增强Lagrange函数</p>
<p>$$<br>\mathcal{L}_{\rho}(x,z,\beta) = f(x) + g(z) + \underline{ \beta^T(Ax+Bz-C) + \frac{\rho}{2} {\Vert Ax+Bz-C \Vert}_2^2 }  \qquad(2.2)<br>$$</p>
<p>从上面形式确实可以看出，ADMM的思想就是想把primal变量、目标函数拆分，但是不再像dual ascent方法那样，将拆分开的\(x_i\)都看做是xx的一部分，后面融合的时候还需要融合在一起，而是最先开始就将拆开的变量分别看做是不同的变量xx和zz，同时约束条件也如此处理，这样的好处就是后面不需要一起融合xx和zz，保证了前面优化过程的可分解性。于是ADMM的优化就变成了如下序贯型迭代（这正是被称作alternating direction的缘故）：</p>
<h4 id="2-2-参数迭代公式（缩放形式）"><a href="#2-2-参数迭代公式（缩放形式）" class="headerlink" title="2.2. 参数迭代公式（缩放形式）"></a>2.2. 参数迭代公式（缩放形式）</h4><p>定义残差：\(\underline{r = Ax+Bz-C}\)，令 \(\underline{\mu = \frac{1}{\rho}\beta} \in R^p\)（对偶变量归一化）. 增强Lagrange函数等价于：</p>
<p>$$<br>\mathcal{L}_{\rho}(x,z,r,\mu) = f(x) + g(z) + \underline{ \frac{\rho}{2} {\Vert r + \mu \Vert}_2^2 - \frac{\rho}{2} {\Vert \mu \Vert}_2^2 }  \qquad(2.3)<br>$$</p>
<blockquote>
<p>推导如下：</p>
<p>$$<br>    \begin{align}<br>    \beta^T(Ax+Bz-C) + \frac{\rho}{2} {\Vert Ax+Bz-C \Vert}_2^2 &amp; = \beta^T \cdot r + \frac{\rho}{2} {\Vert r \Vert}_2^2 \\<br>    &amp; = \frac{\rho}{2} {\left \Vert  r + \frac{1}{\rho} \beta \right \Vert}_2^2 - \frac{1}{2\rho} {\Vert \beta \Vert}_2^2 \\<br>    &amp; = \frac{\rho}{2} {\Vert r + \mu \Vert}_2^2 - \frac{\rho}{2} {\Vert \mu \Vert}_2^2<br>    \end{align}<br>    $$    </p>
</blockquote>
<p>ADMM迭代公式转化为：</p>
<p>$$<br>\begin{cases}<br>    x^{k+1} = \arg \min_{x} \left( f(x) + \frac{\rho}{2} {\Vert Ax^k + Bz^k - C + \mu^k \Vert}_2^2 \right) \qquad (1) \\<br>    z^{k+1} = \arg \min_{z} \left( g(z) + \frac{\rho}{2} {\Vert Ax^{k+1} + Bz^k - C + \mu^k \Vert}_2^2 \right) \qquad(2)\\<br>    \mu^{k+1} = \mu^k + Ax^{k+1} + Bz^{k+1} - C \qquad\qquad\qquad(3)<br>    \end{cases} \qquad(2.4)<br>    $$</p>
<ul>
<li><p>公式(2.4)的理解</p>
<p>  典型的利用ADMM分布式求解的问题中，</p>
<ul>
<li>公式（1）用于各部分数据的<strong>局部参数更新</strong>；</li>
<li>公式（2）用于将个部分得到的局部优化参数综合成<strong>全局的参数</strong>；</li>
<li>公式（3）用于<strong>对偶变量的更新</strong>，是使得整个迭代过程稳定和高效率的关键。</li>
</ul>
</li>
</ul>
<h4 id="2-3-参数迭代公式推导"><a href="#2-3-参数迭代公式推导" class="headerlink" title="2.3. 参数迭代公式推导"></a>2.3. 参数迭代公式推导</h4><ul>
<li><strong>\(f(x)\)为二次函数式时</strong></li>
</ul>
<blockquote>
<p>例如：\(f(x) = \frac{1}{2} x^T P x + q^T x + r\)。损失函数为平方损失时，符合这一场景。</p>
</blockquote>
<p>令\(\underline{-v = Bz^k - C + \mu^k}\)，对参数\(x\)求偏导：</p>
<p>$$<br>\begin{align}<br>\frac{\partial{ \left( f(x) + \frac{\rho}{2} {\Vert Ax - v \Vert}_2^2 \right) }} {\partial{x}}<br>&amp; = \frac{\partial{ \left( \frac{1}{2} x^T P x + q^T x + r + \frac{\rho}{2} {\Vert Ax - v \Vert}_2^2 \right) }} {\partial{x}} \\<br>&amp; = \frac{\partial{(\frac{1}{2} x^T P x)}}{\partial{x}} + \frac{\partial{(q^T x + r)}}{\partial{x}} + \underline{ \frac{\rho}{2} \cdot \frac{(Ax)^T(Ax) - 2(Ax)^Tv + {\Vert v \Vert}_2^2} {\partial{x}} } \\<br>&amp; = Px + (q^T)^T + \underline { \frac{\rho}{2} \left( 2A^TAx - 2A^Tv\right)} \\<br>&amp; = Px + q + \underline{ \rho A^TAx - \rho A^T v } \\<br>&amp; = (P + \rho A^TA)x + (q - \rho A^T v) = 0<br>\end{align}  \qquad(2.5)<br>$$</p>
<p>偏导数为0，得到参数\(x\)的迭代公式：</p>
<p>$$<br>x = (P + \rho A^TA)^{-1} \cdot (\rho A^T v - q) \quad (v中含有参数z和\mu) \qquad(2.6)<br>$$</p>
<blockquote>
</blockquote>
<ul>
<li><p><strong>\(f(x)\)为norm 1范数形式时</strong></p>
<blockquote>
<p>例如：\(f(x) = \lambda {\Vert x \Vert}_{1} = \lambda (|x_1| + |x_2| + \cdots + |x_n|)\)</p>
</blockquote>
<p>  对参数\(x\)求偏导：</p>
<ul>
<li><p>(1). 当\(\frac{\partial {f(x)}} {\partial{x}} = \lambda\)时</p>
<p>$$<br>\begin{align}<br>\frac{\partial{ \left( f(x) + \frac{\rho}{2} {\Vert Ax - v \Vert}_2^2 \right) }} {\partial{x}}<br>&amp; = \frac{\partial{\left( \lambda{\Vert x \Vert}_1 + \frac{\rho}{2} {\Vert Ax - v \Vert}_2^2\right)}} {\partial{x}} \\<br>&amp; = \frac{\partial{(\lambda {\Vert x \Vert}_1)}} {\partial{x}} + \underline{ \frac{\rho}{2} \cdot \frac{(Ax)^T(Ax) - 2(Ax)^Tv + {\Vert v \Vert}_2^2} {\partial{x}} } \\<br>&amp; = \lambda I + \underline{ \rho A^TAx - \rho A^T v } \\<br>&amp; = \rho A^TAx + (\lambda I - \rho A^T v) = 0<br>\end{align} \qquad(2.7)<br>$$</p>
<p>取\(A=I\)，则有</p>
<p>$$<br>x^{*} = I_{n \times p} v - \frac{\lambda}{\rho} I_{n \times 1} &gt; 0  \qquad(2.7-1)<br>$$</p>
</li>
<li><p>(2). 当\(\frac{\partial {f(x)}} {\partial{x}} = -\lambda\)时</p>
<p>$$<br>\begin{align}<br>\frac{\partial{ \left( f(x) + \frac{\rho}{2} {\Vert Ax - v \Vert}_2^2 \right) }} {\partial{x}}<br>&amp; = \frac{\partial{\left( \lambda{\Vert x \Vert}_1 + \frac{\rho}{2} {\Vert Ax - v \Vert}_2^2\right)}} {\partial{x}} \\<br>&amp; = \frac{\partial{(\lambda {\Vert x \Vert}_1)}} {\partial{x}} + \underline{ \frac{\rho}{2} \cdot \frac{(Ax)^T(Ax) - 2(Ax)^Tv + {\Vert v \Vert}_2^2} {\partial{x}} } \\<br>&amp; = -\lambda I + \underline{ \rho A^TAx - \rho A^T v } \\<br>&amp; = \rho A^TAx - (\lambda I + \rho A^T v) = 0<br>\end{align} \qquad(2.8)<br>$$</p>
<p>取\(A=I\)，则有</p>
<p>$$<br>x^{*} = I_{n \times p} v + \frac{\lambda}{\rho} I_{n \times 1} &lt; 0 \qquad(2.8-1)<br>$$</p>
</li>
<li><p>软阈值（Soft Thresholding）</p>
<p>  综合(1)和(2)可得，参数\(x^{*}\)形式为：</p>
<p>  $$<br>  x^{*} = S_{\frac{\lambda}{\rho}}(v) \rightarrow S_{a}(v) = (v-a)_{+} - (-v-a)_{+} =<br>  \begin{cases}<br>  v-a, &amp; \quad if \quad v \ge a \\<br>  \quad 0, &amp;\quad if \quad -a &lt; v &lt; a \\<br>  v+a, &amp; \quad if \quad v \le -a<br>  \end{cases} \qquad(2.9)<br>  $$</p>
<blockquote>
<p>\(a = \frac{\lambda}{\rho}\) 是常数</p>
<p><a href="http://blog.csdn.net/abcjennifer/article/details/8572994" target="_blank" rel="external">软阈值概念与示例</a></p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="3-ADMM-for-Lasso-Model"><a href="#3-ADMM-for-Lasso-Model" class="headerlink" title="3. ADMM for Lasso Model"></a>3. ADMM for Lasso Model</h3><h4 id="3-1-Lasso问题与ADMM"><a href="#3-1-Lasso问题与ADMM" class="headerlink" title="3.1. Lasso问题与ADMM"></a>3.1. Lasso问题与ADMM</h4><p>基于\(l1\)正则的线性回归（即Lasso模型）的目标函数，形式化表示：</p>
<p>$$<br>\min_{w} \; \frac{1}{2} {\Vert Xw - Y\Vert}_2^2 + \lambda {\Vert w \Vert}_1 \qquad(3.1)<br>    $$</p>
<blockquote>
<p>符号解释：<br><br>\(w \in R^n\)：参数向量，n为向量元素个数，即特征数；<br><br>\(X \in R^{m \times n}\)：表示训练数据特征矩阵,m为训练集个数；<br><br>\(Y \in R^m\)：样本label组成的m维向量；<br><br>\(\lambda\)：正则化因子（初始值可通过交叉验证获得）</p>
</blockquote>
<ul>
<li><p>Lasso目标函数格式：”loss + regularization”</p>
<p>  目标函数适用ADMM框架求解形式，改写为</p>
</li>
</ul>
<p>$$<br>    \begin{align}<br>    &amp; \min \quad \overbrace{\frac{1}{2} {\Vert Xw - Y\Vert}_2^2}^{f(w)} + \overbrace{ \lambda {\Vert \theta \Vert}_1}^{g(\theta)} \\<br>    &amp; s.b \qquad w - \theta = 0<br>    \end{align} \qquad(3.2)<br>    $$</p>
<ul>
<li><p>目标函数可分（separable）</p>
<p>  训练数据集切分为\(L\)个部分，分布式训练：</p>
</li>
</ul>
<p>$$<br>    \begin{align}<br>    \frac{1}{2} \sum_{l=1}^{L} {\Vert X_{l} w_l - Y_l\Vert}^2 + \frac{\lambda}{L} \sum_{l=1}^{L} {\Vert w \Vert}_1 = \sum_{l=1}^{L} \left( \underline{ \frac{1}{2} {\Vert X_{l} w_l - Y_l\Vert}^2 + \frac{\lambda}{L} {\Vert w \Vert}_1} \right)<br>    \end{align} \quad(3.3)<br>    $$</p>
<p>这里，\(l=1,2,\cdots,L\)表示数据集划分为\(L\)个子集，\(w_l\)对应于第\(l\)部分数据上得到的参数。</p>
<p>将其改写成分布式ADMM框架可求解的形式。令\(f_l(w_l) = \frac{1}{2} {\Vert X_{l} w_l - Y_l\Vert}^2, g_l(w) = \frac{\lambda}{L} {\Vert w \Vert}_1 \)</p>
<blockquote>
<p>$$<br>    \begin{align}<br>    &amp; \min \quad f_l(w_l) + g_l(\theta) \\<br>    &amp; s.b \qquad w_l - \theta = 0<br>    \end{align} \quad l=1,2,\cdots,L    \qquad(n.3.2)<br>    $$</p>
</blockquote>
<p>每部分数据，对应的增强Lagrange函数为：</p>
<p>$$<br>\mathcal{L}_{\rho}(w_l, \theta, \beta_l) = \frac{1}{2} {\Vert X_l w_l - Y_l\Vert}_2^2 + \frac{\lambda}{L} {\Vert \theta \Vert}_1 + \beta_l^T (w_l-\theta) + \frac{\rho}{2} {\Vert w_l - \theta \Vert}_2^2  \qquad(3.4)<br>$$</p>
<ul>
<li><p>参数\(w\)的迭代公式</p>
<p>  由于\(f(w)\)为二次函数式，即:</p>
<blockquote>
<p>  $$<br>  f(w) = \frac{1}{2} {\Vert Xw - Y\Vert}_2^2 = \frac{1}{2} w^T X^T X w - Y^T Xw + \frac{1}{2} {\Vert Y \Vert}_2^2<br>  $$</p>
</blockquote>
<p>  相应参数</p>
<p>  \(P=X^T X, q=-X^T Y, A=I_{n \times n}, B=-I_{n \times n}, v=\theta^t - \frac{1}{\rho} \beta^t \)。对参数\(w\)求偏导，得到参数\(w\)的迭代公式：</p>
<p>  $$<br>  \begin{align}<br>  w^{k+1} &amp; = (P + \rho A^TA)^{-1} \cdot (\rho A^T v - q) \\<br>  &amp; = (X^T X + \rho I)^{-1} \cdot (\rho v + X^T Y) \\<br>  &amp; = (X^T X + \rho I)^{-1} \cdot \left(X^T Y + \rho(\theta^k - \frac{1}{\rho} \beta^k) \right) \\<br>  &amp; = (X^T X + \rho I)^{-1} \cdot (X^T Y + \rho \theta^k - \beta^k)<br>  \end{align}  \qquad(3.5)<br>  $$</p>
</li>
</ul>
<ul>
<li><p>参数\(\theta\)的迭代公式</p>
<p>  由于\(g(\theta)\)是\(l1\)范数形式，即：</p>
<p>  &gt;<br>  $$<br>  g(\theta) = \lambda {\Vert \theta \Vert}_1 = \lambda (|\theta_1| + |\theta_2| + \cdots + |\theta_n|)<br>$$</p>
</li>
</ul>
<p>$$<br>\theta^{k+1} = S_{\frac{\lambda}{\rho}}(w^{k+1}+\frac{1}{\rho}\beta^k) =<br>\begin{cases}<br>    v-a, &amp; \quad if \quad v \ge a \\<br>    \quad 0, &amp;\quad if \quad -a &lt; v &lt; a \\<br>    v+a, &amp; \quad if \quad v \le -a<br>\end{cases} \qquad(3.6)<br>$$</p>
<ul>
<li><p>参数\(\beta\)的迭代公式</p>
<p>  $$<br>  \beta^{k+1} = \beta^{k} + \rho(w^{k+1} - \theta^{k+1})  \qquad(3.7)<br>  $$</p>
</li>
</ul>
<h4 id="3-2-ADMM分布式更新参数过程"><a href="#3-2-ADMM分布式更新参数过程" class="headerlink" title="3.2. ADMM分布式更新参数过程"></a>3.2. ADMM分布式更新参数过程</h4><p>这里给出参数迭代公式：</p>
<p>$$<br>\begin{align}<br>w_l^{k+1} &amp;= \arg \min_{w} \left( f_l(w) + \frac{\rho}{2} {\Vert w + \theta^k + \mu_l^k \Vert}_2^2 \right) \qquad (1) \\<br>z^{k+1} &amp;= \arg \min_{\theta} \left( g_l(\theta) + \frac{\rho}{2} {\Vert \theta - \overline{w^{k+1}} - \overline{\mu^k} \Vert}_2^2 \right) \quad(2)\\<br>\mu_l^{k+1} &amp;= \mu_l^k + w_l^{k+1} - \theta^{k+1} \qquad\quad\qquad\qquad\qquad(3)<br>\end{align} \qquad(3.8)<br>$$</p>
<p>分布式环境下执行过程：</p>
<ul>
<li>首先，再每个数据分块上，分别执行(1)中对应的更新，得到该数据块上更新后的参数（迭代过程）。这一步是分布式进行的，而且各个数据块之间不需要通信；</li>
<li>然后，根据各部分更新得到的局部参数，执行公式（2）得到综合以后的整体参数\(\theta\)；</li>
<li>最后，根据公式(3)更新对偶变量\(\mu\)（\(\beta的归一化\)），并将更新后的整体参数\(\theta\)和\(\mu\)分发至各个数据块的处理单元。</li>
</ul>
<h4 id="3-3-分布式解决方案"><a href="#3-3-分布式解决方案" class="headerlink" title="3.3. 分布式解决方案"></a>3.3. 分布式解决方案</h4><ul>
<li>MapReduce<ul>
<li>Mapper：（1） </li>
<li>Reducer：（2），（3）</li>
<li>代码示例：<a href="https://github.com/intentmedia/admm.git" target="_blank" rel="external">admm for hadoop</a></li>
</ul>
</li>
<li>MPI： 提供Allreduce和Broadcast操作，用于机器之间的通信<ul>
<li>计算单元：（1） </li>
<li>Allreduce：(2)</li>
<li>Broadcast: (3)</li>
</ul>
</li>
<li>Rabit：<ul>
<li>仅包含MPI的一个Allreduce子集，提供容错；</li>
<li>运行在Yarn上，避免MPI和Hadoop之间的数据传输；</li>
<li>计算过程同MPI；</li>
<li>与DMLC强耦合</li>
<li>示例：<a href="http://10.210.228.76/opticlick/admm/tree/master" target="_blank" rel="external">opticlick-admm@baigang</a></li>
</ul>
</li>
<li>Spark<ul>
<li>单结点：(1)</li>
<li>treeAggregate: (2), 相当于Allreduce</li>
<li>（全局）广播变量 </li>
<li>代码示例：<a href="https://github.com/dieterichlawson/admm" target="_blank" rel="external">admm for spark</a></li>
</ul>
</li>
</ul>
<h4 id="3-4-ADMM适用范围"><a href="#3-4-ADMM适用范围" class="headerlink" title="3.4. ADMM适用范围"></a>3.4. ADMM适用范围</h4><ul>
<li>目标函数结构为”loss + regularation”</li>
<li>目标函数可分：分布式求解</li>
<li>在ML中以loss function是平方损失的模型，都可以用ADMM求解。</li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>







</div>
      <div class="openaside"><a class="navbutton" href="#" title="顯示側邊欄"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隱藏側邊欄"></a></div>
<aside class="clearfix">

  


  

  

  <div class="linkslist">
  <p class="asidetitle">友情鏈接</p>
    <ul>
        
          <li>
            
            	<a href="https://coderq.com" target="_blank" title="一个面向程序员交流分享的新一代社区">码农圈</a>
            
          </li>
        
          <li>
            
            	<a href="http://wuchong.me" target="_blank" title="Jark&#39;s Blog">Jark&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 訂閱</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=null&verifier=b3593ceb&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Larry Page in Google. <br/>
			This is my blog,believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/2176287895" target="_blank" class="icon-weibo" title="微博"></a>
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2016 
		
		<a href="/about" target="_blank" title="John Doe">John Doe</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>










<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回頂部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  <!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
 </html>
